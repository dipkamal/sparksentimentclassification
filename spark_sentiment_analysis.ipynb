{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark sentiment analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a40fGzdOCd6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFpYBdJ7Os0i"
      },
      "source": [
        "First, we use basic data science operations using pandas and numpy to explore the data. We import necessary libraries first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K8PuJ-whstY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdCEuweylRlN"
      },
      "source": [
        "\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj_JKoHwO7T8"
      },
      "source": [
        "Since our dataset is in google drive, we need to connect collab to google drive to access the data. Uploading dataset to collab was slow. Also, such folders are deleted when new session is resumed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqWZ8Q5Xl_aq"
      },
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKSSS7hUqXm3"
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL6kS1x2nYHq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJIbLw0ft923"
      },
      "source": [
        "\n",
        "downloaded = drive.CreateFile({'id':\"1_IY06fo4FPwirTSbGWiGvAqoDeQjbqa0\"}) \n",
        "downloaded.GetContentFile('training.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAbfeVVAPQDS"
      },
      "source": [
        "So, we have extracted the training data files. Now using panda, we read the csv file and assign column names since there is no header in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzJsWG2QuAk1"
      },
      "source": [
        "cols = ['sentiment','id','date','query_string','user','text']\n",
        "\n",
        "df = pd.read_csv(\"/content/training.csv\",engine='python', header=None, names=cols) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFtqyOy_oibl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dae11994-18f5-4bc0-bde7-eda8a7aa3e90"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query_string</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  ...  is upset that he can't update his Facebook by ...\n",
              "2          0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3          0  ...    my whole body feels itchy and like its on fire \n",
              "4          0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzLwnjZuoT0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "722a461f-f21e-486c-a21d-af6556550320"
      },
      "source": [
        "df.sentiment.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLn2IRL-PdPS"
      },
      "source": [
        "We will be analysing the text of tweets so we drop the unrequired columns from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0NBvLzbo1qr"
      },
      "source": [
        "df.drop(['id','date','query_string','user'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrS9IvvSPmgy"
      },
      "source": [
        "#Data preparation\n",
        "\n",
        "First thing we need to do is to prepare the data. We observe the length and type of the text data and conclude following transformation operations to prepare them before analysis.\n",
        "1. Removing HTML decoding in the text\n",
        "2. Mentions removal\n",
        "3. URL links removal\n",
        "4. UTF marks removal\n",
        "5. Hashtag removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeUI1JhivcTk"
      },
      "source": [
        "\n",
        "df['pre_clean_len']=[len(t) for t in df.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcuhbo_1vonc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "603679e4-2023-4abc-eee1-f84393783320"
      },
      "source": [
        "from pprint import pprint\n",
        "data_dict = {\n",
        "    'sentiment':{\n",
        "        'type':df.sentiment.dtype,\n",
        "        'description':'sentiment class - 0:negative, 1:positive'\n",
        "    },\n",
        "    'text':{\n",
        "        'type':df.text.dtype,\n",
        "        'description':'tweet text'\n",
        "    },\n",
        "    'pre_clean_len':{\n",
        "        'type':df.pre_clean_len.dtype,\n",
        "        'description':'Length of the tweet before cleaning'\n",
        "    },\n",
        "    'dataset_shape':df.shape\n",
        "}\n",
        "pprint(data_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_shape': (1600000, 3),\n",
            " 'pre_clean_len': {'description': 'Length of the tweet before cleaning',\n",
            "                   'type': dtype('int64')},\n",
            " 'sentiment': {'description': 'sentiment class - 0:negative, 1:positive',\n",
            "               'type': dtype('int64')},\n",
            " 'text': {'description': 'tweet text', 'type': dtype('O')}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ4ksWBmwM2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d14e8091-d6c7-4d72-a88b-fd366d63f9c0"
      },
      "source": [
        "#check the overall length of the strings with box plot\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "plt.boxplot(df.pre_clean_len)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05l4F6CYwYS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "84bc4e19-bcc3-47b7-bda3-c258b9aae492"
      },
      "source": [
        "\n",
        "#check the tweets that are more than 140 char long\n",
        "df[df.pre_clean_len > 140].head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>pre_clean_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>0</td>\n",
              "      <td>Awwh babs... you look so sad underneith that s...</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>0</td>\n",
              "      <td>Whinging. My client&amp;amp;boss don't understand ...</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0</td>\n",
              "      <td>@TheLeagueSF Not Fun &amp;amp; Furious? The new ma...</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>0</td>\n",
              "      <td>#3 woke up and was having an accident - &amp;quot;...</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>0</td>\n",
              "      <td>My bathtub drain is fired: it haz 1 job 2 do, ...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>0</td>\n",
              "      <td>pears &amp;amp; Brie, bottle of Cabernet, and &amp;quo...</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>0</td>\n",
              "      <td>Have an invite for &amp;quot;Healthy Dining&amp;quot; ...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>0</td>\n",
              "      <td>Damnit I was really digging this season of Rea...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>0</td>\n",
              "      <td>Why do I keep looking...I know that what I rea...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1071</th>\n",
              "      <td>0</td>\n",
              "      <td>Used the term &amp;quot;Fail Whale&amp;quot; to a clie...</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentiment  ... pre_clean_len\n",
              "213           0  ...           142\n",
              "279           0  ...           145\n",
              "343           0  ...           145\n",
              "400           0  ...           144\n",
              "464           0  ...           146\n",
              "492           0  ...           150\n",
              "747           0  ...           141\n",
              "957           0  ...           141\n",
              "1064          0  ...           141\n",
              "1071          0  ...           148\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExrkTU0ySaw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4c95d71-5396-4cc9-f353-4bf5c63d9dcb"
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPvhMpGewinO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3dfd3ebe-782d-4043-d562-f2391dbb3131"
      },
      "source": [
        "\n",
        "\n",
        "from bs4 import BeautifulSoup \n",
        "import re\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[^ ]+'\n",
        "www_pat = r'www.[^ ]+'\n",
        "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
        "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
        "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
        "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
        "                \"mustn't\":\"must not\"}\n",
        "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
        "\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "def tweet_cleaner(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    clean = re.sub(www_pat, '', clean)\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
        "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
        "    # I will tokenize and join together to remove unneccessary white spaces\n",
        "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
        "    return (\" \".join(words)).strip()\n",
        "    \n",
        "testing = df.text[:10]\n",
        "test_result = []\n",
        "for t in testing:\n",
        "    test_result.append(tweet_cleaner(t))\n",
        "test_result\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['awww that bummer you shoulda got david carr of third day to do it',\n",
              " 'is upset that he can update his facebook by texting it and might cry as result school today also blah',\n",
              " 'dived many times for the ball managed to save the rest go out of bounds',\n",
              " 'my whole body feels itchy and like its on fire',\n",
              " 'no it not behaving at all mad why am here because can see you all over there',\n",
              " 'not the whole crew',\n",
              " 'need hug',\n",
              " 'hey long time no see yes rains bit only bit lol fine thanks how you',\n",
              " 'nope they didn have it',\n",
              " 'que me muera']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkCZ3VWTH-tq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7b54de3-75f7-4941-eee9-0fa49b210b2a"
      },
      "source": [
        "nums=[0,1600000]\n",
        "print (\"Cleaning and parsing the tweets\\n\")\n",
        "clean_tweet_texts=[]\n",
        "for i in range(nums[0],nums[1]):\n",
        "  if((i+1)%10000 == 0):\n",
        "    print (\"Tweets %d of %d has been processed\" %(i+1, nums[1]))\n",
        "  clean_tweet_texts.append(tweet_cleaner(df['text'][i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning and parsing the tweets\n",
            "\n",
            "Tweets 10000 of 1600000 has been processed\n",
            "Tweets 20000 of 1600000 has been processed\n",
            "Tweets 30000 of 1600000 has been processed\n",
            "Tweets 40000 of 1600000 has been processed\n",
            "Tweets 50000 of 1600000 has been processed\n",
            "Tweets 60000 of 1600000 has been processed\n",
            "Tweets 70000 of 1600000 has been processed\n",
            "Tweets 80000 of 1600000 has been processed\n",
            "Tweets 90000 of 1600000 has been processed\n",
            "Tweets 100000 of 1600000 has been processed\n",
            "Tweets 110000 of 1600000 has been processed\n",
            "Tweets 120000 of 1600000 has been processed\n",
            "Tweets 130000 of 1600000 has been processed\n",
            "Tweets 140000 of 1600000 has been processed\n",
            "Tweets 150000 of 1600000 has been processed\n",
            "Tweets 160000 of 1600000 has been processed\n",
            "Tweets 170000 of 1600000 has been processed\n",
            "Tweets 180000 of 1600000 has been processed\n",
            "Tweets 190000 of 1600000 has been processed\n",
            "Tweets 200000 of 1600000 has been processed\n",
            "Tweets 210000 of 1600000 has been processed\n",
            "Tweets 220000 of 1600000 has been processed\n",
            "Tweets 230000 of 1600000 has been processed\n",
            "Tweets 240000 of 1600000 has been processed\n",
            "Tweets 250000 of 1600000 has been processed\n",
            "Tweets 260000 of 1600000 has been processed\n",
            "Tweets 270000 of 1600000 has been processed\n",
            "Tweets 280000 of 1600000 has been processed\n",
            "Tweets 290000 of 1600000 has been processed\n",
            "Tweets 300000 of 1600000 has been processed\n",
            "Tweets 310000 of 1600000 has been processed\n",
            "Tweets 320000 of 1600000 has been processed\n",
            "Tweets 330000 of 1600000 has been processed\n",
            "Tweets 340000 of 1600000 has been processed\n",
            "Tweets 350000 of 1600000 has been processed\n",
            "Tweets 360000 of 1600000 has been processed\n",
            "Tweets 370000 of 1600000 has been processed\n",
            "Tweets 380000 of 1600000 has been processed\n",
            "Tweets 390000 of 1600000 has been processed\n",
            "Tweets 400000 of 1600000 has been processed\n",
            "Tweets 410000 of 1600000 has been processed\n",
            "Tweets 420000 of 1600000 has been processed\n",
            "Tweets 430000 of 1600000 has been processed\n",
            "Tweets 440000 of 1600000 has been processed\n",
            "Tweets 450000 of 1600000 has been processed\n",
            "Tweets 460000 of 1600000 has been processed\n",
            "Tweets 470000 of 1600000 has been processed\n",
            "Tweets 480000 of 1600000 has been processed\n",
            "Tweets 490000 of 1600000 has been processed\n",
            "Tweets 500000 of 1600000 has been processed\n",
            "Tweets 510000 of 1600000 has been processed\n",
            "Tweets 520000 of 1600000 has been processed\n",
            "Tweets 530000 of 1600000 has been processed\n",
            "Tweets 540000 of 1600000 has been processed\n",
            "Tweets 550000 of 1600000 has been processed\n",
            "Tweets 560000 of 1600000 has been processed\n",
            "Tweets 570000 of 1600000 has been processed\n",
            "Tweets 580000 of 1600000 has been processed\n",
            "Tweets 590000 of 1600000 has been processed\n",
            "Tweets 600000 of 1600000 has been processed\n",
            "Tweets 610000 of 1600000 has been processed\n",
            "Tweets 620000 of 1600000 has been processed\n",
            "Tweets 630000 of 1600000 has been processed\n",
            "Tweets 640000 of 1600000 has been processed\n",
            "Tweets 650000 of 1600000 has been processed\n",
            "Tweets 660000 of 1600000 has been processed\n",
            "Tweets 670000 of 1600000 has been processed\n",
            "Tweets 680000 of 1600000 has been processed\n",
            "Tweets 690000 of 1600000 has been processed\n",
            "Tweets 700000 of 1600000 has been processed\n",
            "Tweets 710000 of 1600000 has been processed\n",
            "Tweets 720000 of 1600000 has been processed\n",
            "Tweets 730000 of 1600000 has been processed\n",
            "Tweets 740000 of 1600000 has been processed\n",
            "Tweets 750000 of 1600000 has been processed\n",
            "Tweets 760000 of 1600000 has been processed\n",
            "Tweets 770000 of 1600000 has been processed\n",
            "Tweets 780000 of 1600000 has been processed\n",
            "Tweets 790000 of 1600000 has been processed\n",
            "Tweets 800000 of 1600000 has been processed\n",
            "Tweets 810000 of 1600000 has been processed\n",
            "Tweets 820000 of 1600000 has been processed\n",
            "Tweets 830000 of 1600000 has been processed\n",
            "Tweets 840000 of 1600000 has been processed\n",
            "Tweets 850000 of 1600000 has been processed\n",
            "Tweets 860000 of 1600000 has been processed\n",
            "Tweets 870000 of 1600000 has been processed\n",
            "Tweets 880000 of 1600000 has been processed\n",
            "Tweets 890000 of 1600000 has been processed\n",
            "Tweets 900000 of 1600000 has been processed\n",
            "Tweets 910000 of 1600000 has been processed\n",
            "Tweets 920000 of 1600000 has been processed\n",
            "Tweets 930000 of 1600000 has been processed\n",
            "Tweets 940000 of 1600000 has been processed\n",
            "Tweets 950000 of 1600000 has been processed\n",
            "Tweets 960000 of 1600000 has been processed\n",
            "Tweets 970000 of 1600000 has been processed\n",
            "Tweets 980000 of 1600000 has been processed\n",
            "Tweets 990000 of 1600000 has been processed\n",
            "Tweets 1000000 of 1600000 has been processed\n",
            "Tweets 1010000 of 1600000 has been processed\n",
            "Tweets 1020000 of 1600000 has been processed\n",
            "Tweets 1030000 of 1600000 has been processed\n",
            "Tweets 1040000 of 1600000 has been processed\n",
            "Tweets 1050000 of 1600000 has been processed\n",
            "Tweets 1060000 of 1600000 has been processed\n",
            "Tweets 1070000 of 1600000 has been processed\n",
            "Tweets 1080000 of 1600000 has been processed\n",
            "Tweets 1090000 of 1600000 has been processed\n",
            "Tweets 1100000 of 1600000 has been processed\n",
            "Tweets 1110000 of 1600000 has been processed\n",
            "Tweets 1120000 of 1600000 has been processed\n",
            "Tweets 1130000 of 1600000 has been processed\n",
            "Tweets 1140000 of 1600000 has been processed\n",
            "Tweets 1150000 of 1600000 has been processed\n",
            "Tweets 1160000 of 1600000 has been processed\n",
            "Tweets 1170000 of 1600000 has been processed\n",
            "Tweets 1180000 of 1600000 has been processed\n",
            "Tweets 1190000 of 1600000 has been processed\n",
            "Tweets 1200000 of 1600000 has been processed\n",
            "Tweets 1210000 of 1600000 has been processed\n",
            "Tweets 1220000 of 1600000 has been processed\n",
            "Tweets 1230000 of 1600000 has been processed\n",
            "Tweets 1240000 of 1600000 has been processed\n",
            "Tweets 1250000 of 1600000 has been processed\n",
            "Tweets 1260000 of 1600000 has been processed\n",
            "Tweets 1270000 of 1600000 has been processed\n",
            "Tweets 1280000 of 1600000 has been processed\n",
            "Tweets 1290000 of 1600000 has been processed\n",
            "Tweets 1300000 of 1600000 has been processed\n",
            "Tweets 1310000 of 1600000 has been processed\n",
            "Tweets 1320000 of 1600000 has been processed\n",
            "Tweets 1330000 of 1600000 has been processed\n",
            "Tweets 1340000 of 1600000 has been processed\n",
            "Tweets 1350000 of 1600000 has been processed\n",
            "Tweets 1360000 of 1600000 has been processed\n",
            "Tweets 1370000 of 1600000 has been processed\n",
            "Tweets 1380000 of 1600000 has been processed\n",
            "Tweets 1390000 of 1600000 has been processed\n",
            "Tweets 1400000 of 1600000 has been processed\n",
            "Tweets 1410000 of 1600000 has been processed\n",
            "Tweets 1420000 of 1600000 has been processed\n",
            "Tweets 1430000 of 1600000 has been processed\n",
            "Tweets 1440000 of 1600000 has been processed\n",
            "Tweets 1450000 of 1600000 has been processed\n",
            "Tweets 1460000 of 1600000 has been processed\n",
            "Tweets 1470000 of 1600000 has been processed\n",
            "Tweets 1480000 of 1600000 has been processed\n",
            "Tweets 1490000 of 1600000 has been processed\n",
            "Tweets 1500000 of 1600000 has been processed\n",
            "Tweets 1510000 of 1600000 has been processed\n",
            "Tweets 1520000 of 1600000 has been processed\n",
            "Tweets 1530000 of 1600000 has been processed\n",
            "Tweets 1540000 of 1600000 has been processed\n",
            "Tweets 1550000 of 1600000 has been processed\n",
            "Tweets 1560000 of 1600000 has been processed\n",
            "Tweets 1570000 of 1600000 has been processed\n",
            "Tweets 1580000 of 1600000 has been processed\n",
            "Tweets 1590000 of 1600000 has been processed\n",
            "Tweets 1600000 of 1600000 has been processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYreUnxCQPBU"
      },
      "source": [
        "**Now, we save the cleaned data as CSV file which we will be using for the spark analysis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFbAI8e6yI5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3f5d28d4-7d3c-41fb-9f2f-73712f0dee4a"
      },
      "source": [
        "clean_df=pd.DataFrame(clean_tweet_texts, columns=['text'])\n",
        "clean_df['target'] = df.sentiment\n",
        "clean_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>awww that bummer you shoulda got david carr of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can update his facebook by te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dived many times for the ball managed to save ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no it not behaving at all mad why am here beca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  awww that bummer you shoulda got david carr of...       0\n",
              "1  is upset that he can update his facebook by te...       0\n",
              "2  dived many times for the ball managed to save ...       0\n",
              "3     my whole body feels itchy and like its on fire       0\n",
              "4  no it not behaving at all mad why am here beca...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w9wurZAHJ_v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c647bb9-89ba-4002-d941-9a1433e110eb"
      },
      "source": [
        "clean_df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      1600000\n",
              "target    1600000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5H1IoRu89NQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9bdbefd8-0679-46e3-f1f9-c50989a95d01"
      },
      "source": [
        "clean_df.to_csv('clean_tweet.csv',encoding='utf-8')\n",
        "csv = 'clean_tweet.csv'\n",
        "my_df = pd.read_csv(csv,index_col=0)\n",
        "my_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>awww that bummer you shoulda got david carr of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can update his facebook by te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dived many times for the ball managed to save ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no it not behaving at all mad why am here beca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  awww that bummer you shoulda got david carr of...       0\n",
              "1  is upset that he can update his facebook by te...       0\n",
              "2  dived many times for the ball managed to save ...       0\n",
              "3     my whole body feels itchy and like its on fire       0\n",
              "4  no it not behaving at all mad why am here beca...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V-LbYZsQa-z"
      },
      "source": [
        "#Now, we need to install findspark and pyspark on collab since they are not available by default.#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjjsQVvQCcBD"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_yTpgbsD7Pz"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFoUbsA6D-Xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bd987ac-2086-4c8c-c510-b9df9f0dd503"
      },
      "source": [
        "!tar -xvf spark-3.0.0-preview2-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark-3.0.0-preview2-bin-hadoop2.7/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/als/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/graphx/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-vis.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/jars/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/partitioned_users.orc/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/partitioned_users.orc/favorite_color=red/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/partitioned_users.orc/favorite_color=red/users.orc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/partitioned_users.orc/favorite_color=__HIVE_DEFAULT_PARTITION__/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/partitioned_users.orc/favorite_color=__HIVE_DEFAULT_PARTITION__/users.orc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/partitioned_users.orc/do_not_read_this.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scripts/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/slaves.template\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-shims-0.23-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/okapi-shade-0.4.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/orc-core-1.5.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-server-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/scala-library-2.12.10.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/zstd-jni-1.4.4-3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-serde-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/javassist-3.22.0-CR2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/json4s-ast_2.12-3.6.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/snappy-java-1.1.7.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-graph_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-common-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/metrics-json-4.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-exec-2.3.6-core.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/json4s-scalap_2.12-3.6.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-graphx_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/zookeeper-3.4.14.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/velocity-1.5.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-tags_2.12-3.0.0-preview2-tests.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-core_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-unsafe_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/joda-time-2.10.5.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/breeze_2.12-1.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-sql_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-media-jaxb-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-hive_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-hk2-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-mesos_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-yarn_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/metrics-core-4.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/py4j-0.10.8.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-compress-1.8.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/kubernetes-client-4.6.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-sketch_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/kubernetes-model-common-4.6.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-mllib_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-compiler-3.0.15.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/univocity-parsers-2.8.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/json4s-jackson_2.12-3.6.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/arrow-vector-0.15.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-catalyst_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/okhttp-3.12.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-container-servlet-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/json-1.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/json4s-core_2.12-3.6.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-common-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/chill-java-0.9.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/shims-0.7.45.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/logging-interceptor-3.12.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-core-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/arrow-memory-0.15.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-network-common_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-cli-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-service-rpc-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/netty-all-4.1.42.Final.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/RoaringBitmap-0.7.45.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-metastore-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-tags_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-graph-api_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/httpcore-4.4.12.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/kubernetes-model-4.6.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-llap-common-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/okio-1.15.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-repl_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/snakeyaml-1.24.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-container-servlet-core-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/lz4-java-1.7.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/orc-mapreduce-1.5.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/chill_2.12-0.9.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jersey-client-2.29.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-kvstore_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/arrow-format-0.15.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-streaming_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/xz-1.5.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/orc-shims-1.5.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-shims-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-lang3-3.9.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-cypher_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-jdbc-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/janino-3.0.15.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-shims-common-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/antlr4-runtime-4.7.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-beeline-2.3.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/spark-launcher_2.12-3.0.0-preview2.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/hive-storage-api-2.6.0.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/NOTICE\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/.gitignore\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/heapq3.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/resourceinformation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/cloudpickle.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/python/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/python/pyspark/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_cogrouped_map.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_iter.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_map.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/avro/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/cogroup.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/lib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/lib/py4j-0.10.8.1-src.zip\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_coverage/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark.egg-info/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/run-tests\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/setup.cfg\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/run-tests.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/pylintrc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/README.md\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/.coveragerc\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/_static/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/_static/copybutton.js\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/_static/pyspark.js\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/_static/pyspark.css\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/pyspark.ml.rst\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/_templates/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/_templates/layout.html\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/pyspark.sql.rst\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/conf.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/index.rst\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/docs/pyspark.rst\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/setup.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/python/dist/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-sql\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/beeline\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/pyspark\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-submit\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/sparkR\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-class\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/run-example\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-shell\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/RELEASE\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/README.md\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/yarn/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/yarn/spark-3.0.0-preview2-yarn-shuffle.jar\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/LICENSE\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/doc/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/SparkR/doc/index.html\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.0.0-preview2-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QhCJePzEEeT"
      },
      "source": [
        "!pip install -q findspark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LJZWm_yEHjc"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-preview2-bin-hadoop2.7\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH3wOmMUEPnd"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark as ps\n",
        "import warnings\n",
        "from pyspark.sql import SQLContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4WJS29wEqDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b17479e9-1328-41cd-dbd6-920afa7cef26"
      },
      "source": [
        "#we first create a SparkContext that operates in a cluster\n",
        "\n",
        "try: \n",
        "  #create sparkcontext on CPUs available\n",
        "  sc=ps.SparkContext.getOrCreate()\n",
        "  sqlContext=SQLContext(sc)\n",
        "  print(\"Just created a sparkcontet\")\n",
        "except ValueError: \n",
        "  warnings.warn(\"SparkContext already exists\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Just created a sparkcontet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjvcjh9GNXVj"
      },
      "source": [
        "Spark has three different data structures available through its APIs: RDD, Dataframe, Dataset. We can use anyone based on the requirement. RDDs can offer low-level functionality and control but dataframe and dataset offers custom view and structure, offers high level operations, saves space and exectues at superior speeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhhBlE9YFsZn"
      },
      "source": [
        "tweet_df=sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/content/clean_tweet.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJDuHe87GIhM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9995f1ea-4376-4829-ea5c-93bb502add85"
      },
      "source": [
        "type(tweet_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4gtiMAgGcw8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7ac2ec0b-189a-4424-9ff0-d58c9317c657"
      },
      "source": [
        "tweet_df.show(5)\n",
        "tweet_df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+------+\n",
            "|_c0|                text|target|\n",
            "+---+--------------------+------+\n",
            "|  0|awww that bummer ...|     0|\n",
            "|  1|is upset that he ...|     0|\n",
            "|  2|dived many times ...|     0|\n",
            "|  3|my whole body fee...|     0|\n",
            "|  4|no it not behavin...|     0|\n",
            "+---+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1600000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJH1sBx5Gg7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27273c2d-70a7-48fa-b20c-754e418d471a"
      },
      "source": [
        "tweet_df=tweet_df.dropna()\n",
        "tweet_df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1596516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48X-YBV0Go6t"
      },
      "source": [
        "#breaking the datasets into training  and test sets\n",
        "(train_set, test_set)=tweet_df.randomSplit([0.70, 0.30], seed=2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e23FG4FWLpaX"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Iuvzq27MILm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f13ca855-804a-487c-82ba-68552acbcb31"
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
        "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
        "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
        "\n",
        "pipelineFit = pipeline.fit(train_set)\n",
        "train_df = pipelineFit.transform(train_set)\n",
        "test_df = pipelineFit.transform(test_set)\n",
        "train_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
            "|_c0|                text|target|               words|                  tf|            features|label|\n",
            "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
            "|  0|awww that bummer ...|     0|[awww, that, bumm...|(65536,[18354,216...|(65536,[18354,216...|  0.0|\n",
            "|  1|is upset that he ...|     0|[is, upset, that,...|(65536,[1981,3085...|(65536,[1981,3085...|  0.0|\n",
            "|  2|dived many times ...|     0|[dived, many, tim...|(65536,[2548,2888...|(65536,[2548,2888...|  0.0|\n",
            "|  3|my whole body fee...|     0|[my, whole, body,...|(65536,[1880,9243...|(65536,[1880,9243...|  0.0|\n",
            "|  4|no it not behavin...|     0|[no, it, not, beh...|(65536,[1968,8538...|(65536,[1968,8538...|  0.0|\n",
            "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mmkb5D0MN1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de91c0ea-97bd-47d6-efb1-dae51b12853d"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "lrModel = lr.fit(train_df)\n",
        "predictions = lrModel.transform(test_df)\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8546541739482671"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgzm5OgGMzeO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2340adb8-8d98-406d-ed60-f170056682ea"
      },
      "source": [
        "type(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb9vv3o9R7bc"
      },
      "source": [
        "#can be written to a cluster like this\n",
        "#predictions.write.csv(\"hdfs://cluster/usr/hdfs/prediction/result.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wggnZGPtT3_t"
      },
      "source": [
        "BinaryClassificationEvaluator evaluates is by default areaUnderROC. Hence this is not the  measure of accuracy. So, we compute accuracy by counting the number of predictions matching the label and dividing it by the total entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9VQlikvS3pB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73af6519-008f-4e36-9f70-98d3169dfffc"
      },
      "source": [
        "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(test_set.count())\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7853091901546577"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7I15874aOK8"
      },
      "source": [
        "Converting pyspark dataframe to pandas dataframe for visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDASkq7CUDAh"
      },
      "source": [
        "pandas_df = predictions.select(\"*\").toPandas()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0ApniU8e7oA"
      },
      "source": [
        "#plotting confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPL3zCMksUuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10b93c02-bca3-4bfc-ea4b-8ee266ea6854"
      },
      "source": [
        "cnf_matrix=confusion_matrix(pandas_df[\"label\"], pandas_df[\"prediction\"], labels=[1,0])\n",
        "print (cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[191035  48722]\n",
            " [ 54169 185326]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fooBSOYUsb3Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "315010c1-9c3e-491d-ca02-b4cfe01782e9"
      },
      "source": [
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['label=1','label=0'],normalize= False,  title='Confusion matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[191035  48722]\n",
            " [ 54169 185326]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wBpguaIeHJ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "f81f3059-8673-4722-c368-b343b0e006a2"
      },
      "source": [
        "pandas_df.hist(column=\"prediction\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fd732954ac8>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uQp9NE2gFal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "12bfd89e-e9dc-4301-dfce-648b511b0903"
      },
      "source": [
        "\n",
        "pandas_df['clean_len']=[len(t) for t in pandas_df.text]\n",
        "pandas_df.hist(column=\"clean_len\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f4496947630>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLdgPV0ysBeP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}